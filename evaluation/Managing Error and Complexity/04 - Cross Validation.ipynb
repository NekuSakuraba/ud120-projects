{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Problems with splitting into training and testing data;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold CV In Sklearn\n",
    "There's a simple way to randomize the events in sklearn k-fold CV: set the shuffle flag to true.\n",
    "\n",
    "Then you'd go from something like this:\n",
    "\n",
    "cv = KFold( len(authors), 2 )\n",
    "\n",
    "To something like this:\n",
    "\n",
    "cv = KFold( len(authors), 2, shuffle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV is a way of systematically working through multiple combinations of parameter tunes, cross-validating as it goes to determine which tune gives the best performance. The beauty is that it can work through many combinations in only a couple extra lines of code.\n",
    "\n",
    "Here's an example from the sklearn <a href=\"http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html\">documentation</a>:\n",
    "\n",
    "```\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "```\n",
    "\n",
    "Let's break this down line by line.\n",
    "```\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]} \n",
    "```\n",
    "\n",
    "A dictionary of the parameters, and the possible values they may take. In this case, they're playing around with the kernel (possible choices are 'linear' and 'rbf'), and C (possible choices are 1 and 10).\n",
    "\n",
    "Then a 'grid' of all the following combinations of values for (kernel, C) are automatically generated:\n",
    "\n",
    "('rbf', 1)\t('rbf', 10)\n",
    "('linear', 1)\t('linear', 10)\n",
    "\n",
    "Each is used to train an SVM, and the performance is then assessed using cross-validation.\n",
    "```\n",
    "svr = svm.SVC() \n",
    "```\n",
    "This looks kind of like creating a classifier, just like we've been doing since the first lesson. But note that the \"clf\" isn't made until the next line--this is just saying what kind of algorithm to use. Another way to think about this is that the \"classifier\" isn't just the algorithm in this case, it's algorithm plus parameter values. Note that there's no monkeying around with the kernel or C; all that is handled in the next line.\n",
    "```\n",
    "clf = grid_search.GridSearchCV(svr, parameters) \n",
    "```\n",
    "This is where the first bit of magic happens; the classifier is being created. We pass the algorithm (svr) and the dictionary of parameters to try (parameters) and it generates a grid of parameter combinations to try.\n",
    "```\n",
    "clf.fit(iris.data, iris.target)\n",
    "```\n",
    "And the second bit of magic. The fit function now tries all the parameter combinations, and returns a fitted classifier that's automatically tuned to the optimal parameter combination. You can now access the parameter values via\n",
    "```\n",
    "clf.best_params_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz: GridSearchCV in sklearn\n",
    "Refer to the eigenfaces code, which you can find <a href=\"http://scikit-learn.org/0.17/auto_examples/applications/face_recognition.html\">here</a>. What parameters of the SVM are being tuned with GridSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Congratulations on completing this course! In this course you've seen:\n",
    "\n",
    "* Numerical tools for handling large amounts of data efficiently\n",
    "* Different types of data, examples of how they arise, and techniques for using them with standard tools\n",
    "* A variety of metrics for evaluating the performance of different algorithms\n",
    "Basic cross validation techniques for ensuring performance generalizes\n",
    "Visual representations of learning and complexity, and how to use these to pick effective models\n",
    "Great job getting this far! We'll now put these together in a practical project in which you'll go from a dataset to predictions, learn to explain the pros and cons of possible models, and decide on an optimal model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
